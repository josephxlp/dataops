{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cutline filling \n",
    "- what: transect are diagonal, and we want to create 64x64 patches for image models\n",
    "- why: to train image mdoels \n",
    "- where: transect available (RNG) or (TLS)\n",
    "- how: use bbox for the patches > buffer bbox n pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use magic tools to make into a python script \n",
    "import os \n",
    "import subprocess\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box  \n",
    "from glob import glob\n",
    "\n",
    "def clip_raster_by_vector_cutline(raster_fn, out_fn, bbox_fn):\n",
    "    pass \n",
    "\n",
    "def clip_raster_by_vector_bbox(raster_fn, out_fn, bbox_fn):\n",
    "\n",
    "    if not os.path.isfile(out_fn):\n",
    "        bbox = gpd.read_file(bbox_fn)\n",
    "        with rasterio.open(raster_fn) as src:\n",
    "            \n",
    "            bbox = bbox.to_crs(src.crs)\n",
    "            raster_bounds = box(*src.bounds)  # Convert bounds to a Shapely Polygon\n",
    "            raster_gdf = gpd.GeoDataFrame(geometry=[raster_bounds], crs=src.crs)\n",
    "            \n",
    "            # Check if bbox overlaps with raster bounds\n",
    "            if not bbox.intersects(raster_gdf).any():\n",
    "                raise ValueError(f\"No overlap between bbox and raster {raster_fn}\")\n",
    "            \n",
    "            # Clip raster using bbox geometry\n",
    "            out_image, out_transform = mask(src, bbox.geometry, crop=True)\n",
    "            out_meta = src.meta\n",
    "            out_meta.update({\n",
    "                \"driver\": \"GTiff\",\n",
    "                \"height\": out_image.shape[1],\n",
    "                \"width\": out_image.shape[2],\n",
    "                \"transform\": out_transform\n",
    "            })\n",
    "        \n",
    "        # Save clipped raster\n",
    "        with rasterio.open(out_fn, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "\n",
    "\n",
    "def reproject_files_seq(tiff_files, reproj_dir,epsgcode):\n",
    "    #epsgcode = 4326 4979\n",
    "    os.makedirs(reproj_dir, exist_ok=True)\n",
    "    reprojected_files = []\n",
    "    for tiff_file in tiff_files:\n",
    "        # Construct the output file path for the reprojected file\n",
    "        base_name = os.path.splitext(os.path.basename(tiff_file))[0]\n",
    "        reproj_tiff = os.path.join(reproj_dir, f\"{base_name}_reproj.tif\")\n",
    "        gdalreproject(fi=tiff_file, fo=reproj_tiff, epsgcode=epsgcode)\n",
    "        reprojected_files.append(reproj_tiff)\n",
    "    return reprojected_files\n",
    "\n",
    "def reproject_files_par():\n",
    "    pass \n",
    "\n",
    "def gdalreproject(fi, fo, res=1/3600, epsgcode=4749):\n",
    "    \"\"\"\n",
    "    #4749 #4326\n",
    "    Reprojects a raster file using gdalwarp.\n",
    "\n",
    "    Parameters:\n",
    "        fi (str): Input file path.\n",
    "        fo (str): Output file path.\n",
    "        res (float): Resolution for both x and y (default: 1/3600 degrees).\n",
    "        epsgcode (int): EPSG code for the target projection (default: 4326).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    xres = yres = res  # Set x and y resolution to the same value by default\n",
    "\n",
    "    # Check if the output file already exists\n",
    "    if not os.path.isfile(fo):\n",
    "        # Construct the gdalwarp command\n",
    "        cmd_reproject = [\n",
    "            \"gdalwarp\",\n",
    "            \"-t_srs\", f\"EPSG:{epsgcode}\",  # Target spatial reference system\n",
    "            \"-tr\", str(xres), str(yres),  # Resolution for x and y\n",
    "            fi,  # Input file\n",
    "            fo   # Output file\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            # Run the gdalwarp command\n",
    "            subprocess.run(cmd_reproject, check=True)\n",
    "            print(f\"Reprojected {fi} -> \\n{fo}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error reprojecting {fi}: {e}\")\n",
    "            print(f\"Command attempted: {' '.join(cmd_reproject)}\")\n",
    "    else:\n",
    "        print(f\"Output file {fo} already exists. Skipping reprojection.\")\n",
    "\n",
    "# def list2txt(txt, files):\n",
    "#     with open(txt, \"w\") as f:\n",
    "#         f.write(\"\\n\".join(files))\n",
    "\n",
    "def list2txt(txt, files):\n",
    "    with open(txt, \"w\") as f:\n",
    "        for fi in files:\n",
    "            f.write(fi+'\\n')\n",
    "\n",
    "def gdalbuildvrt(vrt, txt, epsgcode):\n",
    "    if not os.path.isfile(vrt):\n",
    "        cmd_vrt = [\n",
    "        \"gdalbuildvrt\",\n",
    "        \"-a_srs\", f\"EPSG:{epsgcode}\",    # Assign the specified EPSG code\n",
    "        \"-input_file_list\", txt,         # Input file list (text file)\n",
    "        vrt                              # Output VRT file\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            # Run the GDAL command to create the VRT\n",
    "            subprocess.run(cmd_vrt, check=True)\n",
    "            print(f\"VRT file created successfully: {vrt}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error creating VRT file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clip variables (VRTs) by transect bbox "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdem_fn= \"/media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRTV2/pdem/pdem.vrt\"\n",
    "s1_fn=  \"/media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRTV2/s1/s1.vrt\"\n",
    "s2_fn = \"/media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRTV2/s2/s2.vrt\"\n",
    "esawc_fn = \"/media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRTV2/esawc/esawc.vrt\"\n",
    "ldem_fn = \"/media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRTV2/ldem/ldem.vrt\"\n",
    "edem_wgs_fn = \"/media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRTV2/edem_wgs/edem_wgs.vrt\"\n",
    "\n",
    "cutline_dir = \"/media/ljp238/12TBWolf/BRCHIEVE/REFERENCE_DEM/cutline/\"\n",
    "bbox_dir = \"/media/ljp238/12TBWolf/BRCHIEVE/REFERENCE_DEM/bbox/\"\n",
    "outdir = exp_dir = \"/media/ljp238/12TBWolf/BRCHIEVE/REFERENCE_DEM/experiment/\"\n",
    "reproj_dir = \"/media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/RNG_reproj\"\n",
    "tiff_files = glob(\"/media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/RNG_OverlapPatchesLiDAR/*.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ljp238/12TBWolf/BRCHIEVE/REFERENCE_DEM/bbox/DTM_NP_T-0007_EPSG5355.gpkg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_files = glob(f\"{bbox_dir}/*DTM_NP*.gpkg\")\n",
    "bbox_fn = bbox_files[0]\n",
    "outdir = exp_dir\n",
    "bbox_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file /media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/RNG_reproj/DTM_NP_T-0007_reproj.tif already exists. Skipping reprojection.\n",
      "Output file /media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/RNG_reproj/DTM_NP_T-0018_reproj.tif already exists. Skipping reprojection.\n",
      "Output file /media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/RNG_reproj/DTM_NP_T-0019_reproj.tif already exists. Skipping reprojection.\n",
      "Output file /media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/RNG_reproj/DTM_NP_T-0020_reproj.tif already exists. Skipping reprojection.\n",
      "Output file /media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/RNG_reproj/DTM_NP_T-0215_reproj.tif already exists. Skipping reprojection.\n",
      "Output file /media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/RNG_reproj/DTM_NP_T-0384_reproj.tif already exists. Skipping reprojection.\n",
      "Output file /media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/RNG_reproj/DTM_NP_T-0388_reproj.tif already exists. Skipping reprojection.\n",
      "Output file /media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/RNG_reproj/DTM_NP_T-0389_reproj.tif already exists. Skipping reprojection.\n"
     ]
    }
   ],
   "source": [
    "txt = 'transects.txt'\n",
    "vrt = 'transects.vrt'\n",
    "epsgcode = 4749#4326\n",
    "reprojected_files = reproject_files_seq(tiff_files, reproj_dir,epsgcode)\n",
    "list2txt(txt, files=reprojected_files)\n",
    "gdalbuildvrt(vrt, txt, epsgcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_from_gpkg(gpkg_path, layer=None, target_epsg=4749):\n",
    "    \"\"\"\n",
    "    Extracts the bounding box from a GeoPackage file and reprojects it to the target EPSG code.\n",
    "\n",
    "    Parameters:\n",
    "        gpkg_path (str): Path to the GeoPackage file.\n",
    "        layer (str): Name of the layer in the GeoPackage (optional).\n",
    "        target_epsg (int): EPSG code to which the bbox should be reprojected.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Bounding box as (xmin, ymin, xmax, ymax) in the target CRS.\n",
    "    \"\"\"\n",
    "    # Read the GeoPackage file\n",
    "    gdf = gpd.read_file(gpkg_path, layer=layer)\n",
    "\n",
    "    # Get the original bounding box\n",
    "    original_bbox = gdf.total_bounds  # Returns [xmin, ymin, xmax, ymax]\n",
    "    print(f\"Original Bounding Box (EPSG:{gdf.crs.to_epsg()}): {original_bbox}\")\n",
    "\n",
    "    # Reproject the GeoDataFrame to the target CRS\n",
    "    gdf = gdf.to_crs(epsg=target_epsg)\n",
    "\n",
    "    # Get the reprojected bounding box\n",
    "    reprojected_bbox = gdf.total_bounds\n",
    "    print(f\"Reprojected Bounding Box (EPSG:{target_epsg}): {reprojected_bbox}\")\n",
    "\n",
    "    return reprojected_bbox\n",
    "\n",
    "def gdal_regrid_by_cutline():\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raster_epsg(raster_path):\n",
    "    \"\"\"\n",
    "    Get the EPSG code of a raster file using rasterio.\n",
    "\n",
    "    Parameters:\n",
    "        raster_path (str): Path to the raster file.\n",
    "\n",
    "    Returns:\n",
    "        int: EPSG code, or None if CRS is undefined.\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        crs = src.crs  # Get the CRS of the raster\n",
    "        if crs:\n",
    "            return crs.to_epsg()  # Convert CRS to EPSG code (if possible)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def gdal_regrid_by_bbox(fi, fo, bbox, ndv=-9999.,res=1/3600, epsgcode=4749):\n",
    "    \"\"\"\n",
    "        Parameters:\n",
    "        fi (str): Input file path.\n",
    "        fo (str): Output file path.\n",
    "        bbox (tuple): Bounding box as (xmin, ymin, xmax, ymax).\n",
    "        res (float): Resolution for both x and y (default: 1/3600 degrees).\n",
    "        epsgcode (int): EPSG code for the target projection (default: 4749).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    xres = yres = res  # Set x and y resolution to the same value by default\n",
    "\n",
    "    # Check if the output file already exists\n",
    "    if not os.path.isfile(fo):\n",
    "        # Construct the gdalwarp command\n",
    "        repsgcode = get_raster_epsg(fi)\n",
    "        print(f\"{repsgcode}=={epsgcode}?\")\n",
    "        if epsgcode == repsgcode:\n",
    "            cmd_reproject = [\"gdalwarp\",\"-tap\",\n",
    "                             \"-tr\", str(xres), str(yres),\n",
    "                             \"-te\", str(xmin), str(ymin), str(xmax), str(ymax),\n",
    "                             \"-dstnodata\", str(ndv),fi, fo ]\n",
    "        else:\n",
    "            cmd_reproject = [\"gdalwarp\",\"-tap\",\n",
    "                             \"-t_srs\", f\"EPSG:{epsgcode}\",  \n",
    "                             \"-te_srs\", f\"EPSG:{epsgcode}\",\n",
    "                             \"-tr\", str(xres), str(yres),  \n",
    "                             \"-te\", str(xmin), str(ymin), str(xmax), str(ymax),\n",
    "                             \"-dstnodata\", str(ndv),fi, fo ]\n",
    "        try:\n",
    "            # Run the gdalwarp command\n",
    "            subprocess.run(cmd_reproject, check=True)\n",
    "            print(f\"Reprojected {fi} -> \\n{fo}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error reprojecting {fi}: {e}\")\n",
    "            print(f\"Command attempted: {' '.join(cmd_reproject)}\")\n",
    "    else:\n",
    "        print(f\"Output file {fo} already exists. Skipping reprojection.\")\n",
    "\n",
    "def regrid(fi, fo, bbox, ndv=-9999.,res=1/3600, epsgcode=4749):\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    xres = yres = res \n",
    "    repsgcode = get_raster_epsg(fi)\n",
    "    cmd_reproject = [\n",
    "    \"gdalwarp\",\n",
    "    \"-tap\",\n",
    "    \"-s_srs\", f\"EPSG:{repsgcode}\",\n",
    "    \"-t_srs\", f\"EPSG:{epsgcode}\",\n",
    "    \"-tr\", str(xres), str(yres),\n",
    "    \"-te_srs\", f\"EPSG:{epsgcode}\",\n",
    "    \"-te\", str(xmin), str(ymin), str(xmax), str(ymax),\n",
    "    \"-dstnodata\", str(ndv),\n",
    "    fi, fo]\n",
    "    try:\n",
    "        # Run the gdalwarp command\n",
    "        subprocess.run(cmd_reproject, check=True)\n",
    "        print(f\"Reprojected {fi} -> \\n{fo}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error reprojecting {fi}: {e}\")\n",
    "        print(f\"Command attempted: {' '.join(cmd_reproject)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#bbox = get_bbox_from_gpkg(bbox_fn)\n",
    "#gdal_regrid_by_bbox(fi=vrt, fo=f\"{outdir}/clipped_ldem.tif\",bbox=bbox)\n",
    "#gdal_regrid_by_bbox(fi=s1_fn, fo=f\"{outdir}/clipped_s1.tif\",bbox=bbox)\n",
    "#gdal_regrid_by_bbox(fi=edem_wgs_fn, fo=f\"{outdir}/clipped_edem.tif\",bbox=bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_raster_by_vector_bbox(s1_fn, f\"{outdir}/clipped_s1.tif\", bbox_fn)\n",
    "clip_raster_by_vector_bbox(edem_wgs_fn, f\"{outdir}/clipped_edem.tif\", bbox_fn)\n",
    "clip_raster_by_vector_bbox(vrt, f\"{outdir}/clipped_ldem.tif\", bbox_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build it step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file /media/ljp238/12TBWolf/BRCHIEVE/REFERENCE_DEM/experiment//clipped_zdif.tif already exists. Skipping computation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "\n",
    "# Define paths\n",
    "dtm_path = f\"{outdir}/clipped_ldem.tif\"  # 1-band DTM reference\n",
    "dsm_path = f\"{outdir}/clipped_edem.tif\"  # 1-band DSM\n",
    "dif_path = f\"{outdir}/clipped_zdif.tif\"    # Output path for DSM - DTM\n",
    "\n",
    "if not os.path.exists(dif_path):\n",
    "    with rasterio.open(dsm_path) as dsm_src, rasterio.open(dtm_path) as dtm_src:\n",
    "        # Validate that the rasters are compatible\n",
    "        if dsm_src.shape != dtm_src.shape:\n",
    "            raise ValueError(\"Input rasters do not have the same dimensions.\")\n",
    "        if dsm_src.crs != dtm_src.crs:\n",
    "            raise ValueError(\"Input rasters do not have the same CRS.\")\n",
    "        # if ra_src.transform != rb_src.transform:\n",
    "        #     raise ValueError(\"Input rasters do not have the same transform.\")\n",
    "\n",
    "        # Read the raster data\n",
    "        dsm = dsm_src.read(1)  # Read the first band of DTM\n",
    "        dtm = dtm_src.read(1)  # Read the first band of DSM\n",
    "\n",
    "        # Compute the difference (DSM - DTM)\n",
    "        dif = dsm - dtm\n",
    "        ndv = -9999.\n",
    "        dif[dtm < -99.] = ndv\n",
    "        dif[dtm > 10000] = ndv\n",
    "\n",
    "        # Copy metadata from one of the input rasters\n",
    "        out_meta = dsm_src.meta\n",
    "        out_meta.update({'nodata':ndv})\n",
    "\n",
    "    # Write the result to ypath\n",
    "    with rasterio.open(ypath, \"w\", **out_meta) as dst:\n",
    "        dst.write(dif, 1)\n",
    "\n",
    "    print(f\"Computed difference raster saved to {ypath}\")\n",
    "else:\n",
    "    print(f\"Output file {dif_path} already exists. Skipping computation.\")\n",
    "# make it into a function called create_zdiff \n",
    "# make it so that the new nodata value works well in soft like QGIS\n",
    "# and keep only zdiff values for where dtm are valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file /media/ljp238/12TBWolf/BRCHIEVE/REFERENCE_DEM/experiment//clipped_zdif.tif already exists. Skipping computation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "\n",
    "def create_zdiff(dsm_path, dtm_path, dif_path, ndv=-9999.0):\n",
    "    \"\"\"\n",
    "    Computes the difference (DSM - DTM) and saves it to the specified output path.\n",
    "    \n",
    "    Parameters:\n",
    "        dsm_path (str): Path to the DSM raster file.\n",
    "        dtm_path (str): Path to the DTM raster file.\n",
    "        dif_path (str): Path to save the difference raster (DSM - DTM).\n",
    "        ndv (float): Nodata value for the output raster (default is -9999.0).\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Check if the output file already exists\n",
    "    if os.path.exists(dif_path):\n",
    "        print(f\"Output file {dif_path} already exists. Skipping computation.\")\n",
    "        return\n",
    "\n",
    "    # Open the input rasters\n",
    "    with rasterio.open(dsm_path) as dsm_src, rasterio.open(dtm_path) as dtm_src:\n",
    "        # Validate that the rasters are compatible\n",
    "        if dsm_src.shape != dtm_src.shape:\n",
    "            raise ValueError(\"Input rasters do not have the same dimensions.\")\n",
    "        if dsm_src.crs != dtm_src.crs:\n",
    "            raise ValueError(\"Input rasters do not have the same CRS.\")\n",
    "        if dsm_src.transform != dtm_src.transform:\n",
    "            raise ValueError(\"Input rasters do not have the same transform.\")\n",
    "\n",
    "        # Read the raster data\n",
    "        dsm = dsm_src.read(1)  # Read the first band of DSM\n",
    "        dtm = dtm_src.read(1)  # Read the first band of DTM\n",
    "\n",
    "        # Compute the difference (DSM - DTM)\n",
    "        dif = dsm - dtm\n",
    "\n",
    "        # Apply nodata mask: retain only valid DTM values\n",
    "        valid_mask = (dtm > -99.) & (dtm < 10000)  # Define valid DTM range\n",
    "        dif[~valid_mask] = ndv  # Set invalid areas to nodata\n",
    "\n",
    "        # Copy metadata from one of the input rasters and update nodata value\n",
    "        out_meta = dsm_src.meta\n",
    "        out_meta.update({\n",
    "            'nodata': ndv,\n",
    "            'dtype': 'float32'  # Ensure output dtype is float32 for better GIS compatibility\n",
    "        })\n",
    "\n",
    "    # Write the result to the output path\n",
    "    with rasterio.open(dif_path, \"w\", **out_meta) as dst:\n",
    "        dst.write(dif.astype('float32'), 1)\n",
    "\n",
    "    print(f\"Computed difference raster saved to {dif_path}\")\n",
    "\n",
    "dsm_path = f\"{outdir}/clipped_edem.tif\"\n",
    "dtm_path = f\"{outdir}/clipped_ldem.tif\"\n",
    "dif_path = f\"{outdir}/clipped_zdif.tif\"\n",
    "\n",
    "create_zdiff(dsm_path, dtm_path, dif_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why chm (dsm-dtm) is lower than dtm ? should it it be higher than dtm and lower than dsm? so what's up with that? make it make sense because it not supposed to physically. context I am wrking with rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_path = f\"{outdir}/clipped_edem.tif\" # feature  1band\n",
    "dtm_path = f\"{outdir}/clipped_ldem.tif\" # reference 1band\n",
    "dif_path = f\"{outdir}/clipped_zdif.tif\" # target 1band\n",
    "s1_path = f\"{outdir}/clipped_s1.tif\" # feature 2bands \n",
    "mlpath = f\"{outdir}/clipped_tabml.tif\"\n",
    "\n",
    "# read dif_path as taget, create mask of vaid to invalid pixls based on nvd and anything below -99 and above 5000\n",
    "# read dsm_path and s1_path as feature and filter out the by the mask above \n",
    "\n",
    "# train feature with target on valid pixels : use catboost regressor iterations 2000\n",
    "# predict on all the feature ()\n",
    "# do dsm - pred and write the output to tif with dsm propertoes to mlpath\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.03303\n",
      "0:\tlearn: 4.5602570\ttotal: 50.9ms\tremaining: 1m 41s\n",
      "100:\tlearn: 1.8505793\ttotal: 289ms\tremaining: 5.44s\n",
      "200:\tlearn: 1.7515871\ttotal: 501ms\tremaining: 4.48s\n",
      "300:\tlearn: 1.7110827\ttotal: 710ms\tremaining: 4s\n",
      "400:\tlearn: 1.6817320\ttotal: 918ms\tremaining: 3.66s\n",
      "500:\tlearn: 1.6587208\ttotal: 1.13s\tremaining: 3.37s\n",
      "600:\tlearn: 1.6398366\ttotal: 1.34s\tremaining: 3.11s\n",
      "700:\tlearn: 1.6215031\ttotal: 1.55s\tremaining: 2.87s\n",
      "800:\tlearn: 1.6034715\ttotal: 1.76s\tremaining: 2.63s\n",
      "900:\tlearn: 1.5883158\ttotal: 1.97s\tremaining: 2.4s\n",
      "1000:\tlearn: 1.5732051\ttotal: 2.19s\tremaining: 2.19s\n",
      "1100:\tlearn: 1.5583849\ttotal: 2.4s\tremaining: 1.96s\n",
      "1200:\tlearn: 1.5444019\ttotal: 2.61s\tremaining: 1.74s\n",
      "1300:\tlearn: 1.5305429\ttotal: 2.82s\tremaining: 1.51s\n",
      "1400:\tlearn: 1.5168516\ttotal: 3.03s\tremaining: 1.29s\n",
      "1500:\tlearn: 1.5033568\ttotal: 3.24s\tremaining: 1.08s\n",
      "1600:\tlearn: 1.4894817\ttotal: 3.44s\tremaining: 859ms\n",
      "1700:\tlearn: 1.4773276\ttotal: 3.66s\tremaining: 643ms\n",
      "1800:\tlearn: 1.4650220\ttotal: 3.87s\tremaining: 428ms\n",
      "1900:\tlearn: 1.4539618\ttotal: 4.08s\tremaining: 213ms\n",
      "1999:\tlearn: 1.4434236\ttotal: 4.29s\tremaining: 0us\n",
      "Prediction results saved to /media/ljp238/12TBWolf/BRCHIEVE/REFERENCE_DEM/experiment//clipped_tabml.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from skimage.transform import resize\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def read_raster(file_path):\n",
    "    \"\"\"Reads a raster file and returns the array and metadata.\"\"\"\n",
    "    with rasterio.open(file_path) as src:\n",
    "        array = src.read(1)\n",
    "        profile = src.profile\n",
    "        return array, profile\n",
    "\n",
    "def resize_raster(src_array, target_shape):\n",
    "    \"\"\"Resizes a raster array to match the target shape using interpolation.\"\"\"\n",
    "    resized_array = resize(\n",
    "        src_array, \n",
    "        target_shape, \n",
    "        order=1,  # Bilinear interpolation\n",
    "        mode='constant', \n",
    "        anti_aliasing=True\n",
    "    )\n",
    "    return resized_array\n",
    "\n",
    "def preprocess_data(dif_path, dsm_path, s1_path):\n",
    "    \"\"\"Reads and processes input raster data.\"\"\"\n",
    "    dif, profile = read_raster(dif_path)\n",
    "    dsm, _ = read_raster(dsm_path)\n",
    "    \n",
    "    # Read Sentinel-1 bands\n",
    "    with rasterio.open(s1_path) as src:\n",
    "        s1_band1 = src.read(1)\n",
    "        s1_band2 = src.read(2) if src.count > 1 else src.read(1)  # Handle single-band files\n",
    "    \n",
    "    # Resize Sentinel-1 bands to match DSM dimensions\n",
    "    target_shape = dsm.shape\n",
    "    s1_band1_resized = resize_raster(s1_band1, target_shape)\n",
    "    s1_band2_resized = resize_raster(s1_band2, target_shape)\n",
    "    \n",
    "    # Create a valid mask based on the difference raster\n",
    "    valid_mask = (dif > -99) & (dif < 5000)\n",
    "    \n",
    "    # Extract valid values\n",
    "    valid_dsm = dsm[valid_mask]\n",
    "    valid_s1_band1 = s1_band1_resized[valid_mask]\n",
    "    valid_s1_band2 = s1_band2_resized[valid_mask]\n",
    "    valid_dif = dif[valid_mask]\n",
    "    \n",
    "    # Combine features\n",
    "    X_train = np.column_stack((valid_dsm, valid_s1_band1, valid_s1_band2))\n",
    "    y_train = valid_dif\n",
    "    \n",
    "    return X_train, y_train, dsm, s1_band1_resized, s1_band2_resized, profile\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"Trains a CatBoost model.\"\"\"\n",
    "    model = CatBoostRegressor(iterations=2000, verbose=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def predict_model(model, dsm, s1_band1, s1_band2):\n",
    "    \"\"\"Generates predictions for the entire raster grid.\"\"\"\n",
    "    all_features = np.column_stack((dsm.flatten(), s1_band1.flatten(), s1_band2.flatten()))\n",
    "    predictions = model.predict(all_features).reshape(dsm.shape)\n",
    "    return predictions\n",
    "\n",
    "def save_raster(output_path, array, profile):\n",
    "    \"\"\"Saves a raster file with the specified profile.\"\"\"\n",
    "    profile.update(dtype=rasterio.float32, nodata=-9999.0)\n",
    "    with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "        dst.write(array.astype('float32'), 1)\n",
    "\n",
    "def transect_augment_data(dif_path, dsm_path, s1_path, output_path):\n",
    "    \"\"\"Main function to process rasters, train a model, and generate predictions.\"\"\"\n",
    "    # Step 1: Preprocess data\n",
    "    X_train, y_train, dsm, s1_band1_resized, s1_band2_resized, profile = preprocess_data(dif_path, dsm_path, s1_path)\n",
    "\n",
    "    # Step 2: Train model\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    # Step 3: Predict and save results\n",
    "    predictions = predict_model(model, dsm, s1_band1_resized, s1_band2_resized)\n",
    "    dsm_pred_diff = dsm - predictions\n",
    "    save_raster(output_path, dsm_pred_diff, profile)\n",
    "    print(f\"Prediction results saved to {output_path}\")\n",
    "\n",
    "    # add the dowscaling ml here @ do the saving models latter \n",
    "\n",
    "\n",
    "transect_augment_data(dif_path, dsm_path, s1_path, mlpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from uvars import topoxcale_dir \n",
    "sys.path.append(topoxcale_dir)\n",
    "from topoxcale.mlxcale import mldownxcale\n",
    "from topoxcale.sagaxcale import gwrdownxcale\n",
    "\n",
    "#4749 or  4979\n",
    "num_rounds = 2000\n",
    "n = 0  # Set to 0 to use all data\n",
    "sfix2 = \"GWR\"\n",
    "sfix1 = \"MLdx\"\n",
    "model_params = {'num_rounds': num_rounds,'verbose': 200}\n",
    "x_path = dsm_path\n",
    "y_path = mlpath\n",
    "model_name = y_path.replace('tif', f'_{num_rounds}.pkl')\n",
    "out_path = y_path.replace('.tif', f'_{sfix1}.tif')\n",
    "out_path2 = y_path.replace('.tif', f'_{sfix2}.tif')\n",
    "#mldownxcale(x_path, y_path, model_name, model_params, out_path, n=0): fix the error\n",
    "gwrdownxcale(xpath=dsm_path, ypath=mlpath, opath=out_path2,oaux=False,epsg_code=4749, clean=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gwr downscaling much smoother and better for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ljp238/12TBWolf/BRCHIEVE/REFERENCE_DEM/experiment//clipped_edem.tif'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the weighted mdoels with the paper [x]\n",
    "# do the dwx - just grab the codes from the other project [x]\n",
    "# do the todo list to clear up stuff \n",
    "# leave this stuff running \n",
    "# load into Onedrive and write data augmentation A, and then do B(increment by gridsize)\n",
    "\n",
    "### do incremental learning for this stuff https://catboost.ai/docs/en/concepts/python-reference_catboostregressor_fit\n",
    "## predict with gmodel, and check error\n",
    "## train lmodel, and check the error\n",
    "## pred with gmodel and check the error \n",
    "## pick the best of the two base on residual map (cout wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
